{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount the drive that contains the data.\n"
      ],
      "metadata": {
        "id": "Wsu4x0jLchLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R3ZaiLgFbJ_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and load all the required packages."
      ],
      "metadata": {
        "id": "ZATPGWaycitg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-rUjQ2ICzZ4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, Lambda\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize all the images to 224x224 and add a preprocessing layer."
      ],
      "metadata": {
        "id": "ab9aTJyzcjmf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGmqoOgDEif"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the path to the file containing the data.\n",
        "Split the available data into training data, testing data and validation data and reset the index."
      ],
      "metadata": {
        "id": "CMoBq0zpckvz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMIA-Z7eDFZt"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Mixed Images\"\n",
        "filenames = os.listdir(path)\n",
        "\n",
        "df=pd.DataFrame({'filename':filenames})\n",
        "df[\"category\"] = df.apply(lambda x: x['filename'].split('_')[0], axis=1)\n",
        "\n",
        "temp1 = df[df.category=='Damaged']\n",
        "temp2 = df[df.category=='Undamaged']\n",
        "df = pd.concat([temp1, temp2],ignore_index=True, axis = 0)\n",
        "df.category.value_counts()\n",
        "\n",
        "train_df, validate_df = train_test_split(df, test_size=0.30, random_state=42, stratify=df[\"category\"])\n",
        "validate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42, stratify=validate_df[\"category\"])\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVPduZyUDcSs"
      },
      "outputs": [],
      "source": [
        "print(train_df.category.value_counts())\n",
        "print(validate_df.category.value_counts())\n",
        "print(test_df.category.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image augmentation using the Image data generator function."
      ],
      "metadata": {
        "id": "NmwOS5_ycmXp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbFujP5mDflG"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator( rotation_range=15,\n",
        "                                    rescale=1./255,\n",
        "                                    shear_range=0.1,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip = True,\n",
        "                                    width_shift_range=0.1,\n",
        "                                    height_shift_range=0.1)\n",
        "\n",
        "train_set = train_datagen.flow_from_dataframe(train_df,path,x_col='filename',y_col='category',\n",
        "                                              target_size=(224, 224),class_mode='categorical',batch_size=32)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_set = validation_datagen.flow_from_dataframe(validate_df,path,x_col='filename',\n",
        "                                                        y_col='category',target_size=(224, 224),\n",
        "                                                        class_mode='categorical',batch_size=32,\n",
        "                                                        seed = 342)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_dataframe(test_df,path,x_col='filename',\n",
        "                                            y_col='category',target_size=(224, 224),\n",
        "                                            class_mode='categorical',batch_size=32, \n",
        "                                            shuffle=False, seed = 342)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwiClIt8DkD2",
        "outputId": "fbec511f-b1f6-4aad-a05b-cce336b4b1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Add dropout layers\n",
        "\n",
        "# x = Dense(1024, activation='relu')(vgg.output)\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "x = Flatten()(vgg.output)\n",
        "\n",
        "prediction = Dense(len(train_df.category.value_counts()), activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model and use early stopping callback to stop training once the model performance stops improving."
      ],
      "metadata": {
        "id": "Ech7R4JGcpf1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjTvIjtWDnU_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-04), metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5, restore_best_weights=True)\n",
        "\n",
        "r = model.fit(train_set,\n",
        "              validation_data=validation_set,\n",
        "              epochs=18,\n",
        "              steps_per_epoch=len(train_set),\n",
        "              validation_steps=len(validation_set),\n",
        "              callbacks=[callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss and accuracy graphs to visualize the performance of the model."
      ],
      "metadata": {
        "id": "ZkA3r0CRctTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dst6Z8TuPsYz"
      },
      "outputs": [],
      "source": [
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/VGG_ValLoss_2.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7hdgy-RP2VK"
      },
      "outputs": [],
      "source": [
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/VGG_ValACC_2.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained model on the drive."
      ],
      "metadata": {
        "id": "q3iA8JegcwHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcz7qDaSP60s"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/VGG16_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKZxphTFP_h3"
      },
      "outputs": [],
      "source": [
        "train_set.class_indices.items()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the saved model and make predictions on the test dataset."
      ],
      "metadata": {
        "id": "-M2DKW4EcyHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rtEKI-sQDJx"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/VGG16/VGG16_2.h5')\n",
        "test_set.reset()\n",
        "pred = model.predict(test_set)\n",
        "test_df[\"pred\"] = np.argmax(pred, axis=1)\n",
        "test_df[\"pred\"] = test_df[\"pred\"].replace({0:'Damaged',1:'Undamaged'})\n",
        "test_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbU_xD_uILHQ"
      },
      "outputs": [],
      "source": [
        "mis = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMqumSOQSpkv"
      },
      "outputs": [],
      "source": [
        "k = test_df['category'] != test_df['pred']\n",
        "mis.append(test_df[k]['filename'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qse9rOzgHv_F"
      },
      "outputs": [],
      "source": [
        "mis[0][:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXfxwxnBKRst"
      },
      "outputs": [],
      "source": [
        "mis[0][50:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwU-lfhkJgHC"
      },
      "outputs": [],
      "source": [
        "test_df.to_csv(\"/content/drive/MyDrive/VGG16/test_set.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssyGyDdgTNub"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_set, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a confusion matrix to understand the model predictions."
      ],
      "metadata": {
        "id": "k1xxu_0Gc2Ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aiomrc4Ud1R"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_df['category'], test_df['pred'])\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wre4DPcWUgKo"
      },
      "outputs": [],
      "source": [
        "target_names = ['Damaged', 'Undamaged']\n",
        "classification_report(test_df['category'], test_df['pred'], target_names= target_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-S_1g9ukN7W"
      },
      "outputs": [],
      "source": [
        "#              precision    recall  f1-score   support\n",
        "\n",
        "#     Damaged       0.79      0.72      0.75       234\n",
        "#   Undamaged       0.73      0.80      0.76       226\n",
        "\n",
        "#    accuracy                           0.76       460\n",
        "#   macro avg       0.76      0.76      0.76       460\n",
        "#weighted avg       0.76      0.76      0.76       460\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the predictions made by the model."
      ],
      "metadata": {
        "id": "I-O5C-mQc5cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G0o4RnCMUoHf"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "sample_test = test_df.sample(n=20).reset_index(drop=True)\n",
        "plt.figure(figsize=(20, 20))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    pred = row['pred']\n",
        "    img = image.load_img(path + \"/\" + filename, target_size=(224,224))\n",
        "    plt.subplot(4, 5, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename.split(' ')[0] + '(' + \"{}\".format(pred) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of Image augmentation."
      ],
      "metadata": {
        "id": "XlY3X4WedBRO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W654pKiSUuJE"
      },
      "outputs": [],
      "source": [
        "# Image Augmentation\n",
        "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
        "example_set = train_datagen.flow_from_dataframe(\n",
        "    example_df, \n",
        "    path,\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=(224,224),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 15):\n",
        "    plt.subplot(5, 3, i+1)\n",
        "    for X_batch, Y_batch in example_set:\n",
        "        image = X_batch[0]\n",
        "        plt.imshow(image)\n",
        "        break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdLcynFAU_NN"
      },
      "outputs": [],
      "source": [
        "vgg = tf.keras.models.load_model('/content/drive/MyDrive/VGG16/VGG16_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL9pbb4qn1Wt"
      },
      "outputs": [],
      "source": [
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayDZORhrom9O"
      },
      "outputs": [],
      "source": [
        "last_conv_layer = vgg.get_layer(\"block5_conv3\")\n",
        "last_conv_layer_model = tf.keras.Model(vgg.inputs, last_conv_layer.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1QhnpVLovQ6"
      },
      "outputs": [],
      "source": [
        "classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "x = classifier_input\n",
        "y = vgg.get_layer(\"block5_pool\")(x)\n",
        "y = Flatten()(y)\n",
        "# y = Dense(4096, activation='relu')(y)\n",
        "y = Dense(3, activation='sigmoid')(y)\n",
        "classifier_model = tf.keras.Model(classifier_input, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grad-CAM mapping"
      ],
      "metadata": {
        "id": "f025bxMrdH9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnWmP8X2o3Sv"
      },
      "outputs": [],
      "source": [
        "def gradCam(image):  \n",
        "  with tf.GradientTape() as tape:\n",
        "      inputs = image[np.newaxis, ...]\n",
        "      last_conv_layer_output = last_conv_layer_model(inputs)\n",
        "      tape.watch(last_conv_layer_output)\n",
        "      preds = classifier_model(last_conv_layer_output)\n",
        "      top_pred_index = tf.argmax(preds[0])\n",
        "      top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "  grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "  pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "  last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "  pooled_grads = pooled_grads.numpy()\n",
        "  for i in range(pooled_grads.shape[-1]):\n",
        "      last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "  gradcam = np.mean(last_conv_layer_output, axis=-1)\n",
        " \n",
        "  gradcam = np.clip(gradcam, 0, np.max(gradcam)) / np.max(gradcam)\n",
        "  gradcam = cv2.resize(gradcam, (224, 224))\n",
        "\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(gradcam, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guided Grad-CAM mapping"
      ],
      "metadata": {
        "id": "axbV-3VQdJIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is0FZrsbo3VS"
      },
      "outputs": [],
      "source": [
        "def guidedGradCam(image):  \n",
        "  with tf.GradientTape() as tape:\n",
        "      last_conv_layer_output = last_conv_layer_model(image[np.newaxis, ...])\n",
        "      tape.watch(last_conv_layer_output)\n",
        "      preds = classifier_model(last_conv_layer_output)\n",
        "      top_pred_index = tf.argmax(preds[0])\n",
        "      top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "  grads = tape.gradient(top_class_channel, last_conv_layer_output)[0]\n",
        "  last_conv_layer_output = last_conv_layer_output[0]\n",
        "\n",
        "  guided_grads = (\n",
        "      tf.cast(last_conv_layer_output > 0, \"float32\")\n",
        "      * tf.cast(grads > 0, \"float32\")\n",
        "      * grads\n",
        "  )\n",
        "\n",
        "  pooled_guided_grads = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "  guided_gradcam = np.ones(last_conv_layer_output.shape[:2], dtype=np.float32)\n",
        "\n",
        "  for i, w in enumerate(pooled_guided_grads):\n",
        "      guided_gradcam += w * last_conv_layer_output[:, :, i]\n",
        "\n",
        "  guided_gradcam = cv2.resize(guided_gradcam.numpy(), (224, 224))\n",
        "\n",
        "  guided_gradcam = np.clip(guided_gradcam, 0, np.max(guided_gradcam))\n",
        "  guided_gradcam = (guided_gradcam - guided_gradcam.min()) / (\n",
        "      guided_gradcam.max() - guided_gradcam.min()\n",
        "  )\n",
        "\n",
        "\n",
        "  @tf.custom_gradient\n",
        "  def guided_relu(x):\n",
        "      def grad(dy):\n",
        "          return tf.cast(dy > 0, \"float32\") * tf.cast(x > 0, \"float32\") * dy\n",
        "\n",
        "      return tf.nn.relu(x), grad\n",
        "\n",
        "  class GuidedBackprop:\n",
        "      def __init__(self, model, layer_name: str):\n",
        "          self.model = model\n",
        "          self.layer_name = layer_name\n",
        "          self.gb_model = self.build_guided_model()\n",
        "\n",
        "      def build_guided_model(self):\n",
        "          gb_model = tf.keras.Model(\n",
        "              self.model.inputs, self.model.get_layer(self.layer_name).output\n",
        "          )\n",
        "          layers = [\n",
        "              layer for layer in gb_model.layers[1:] if hasattr(layer, \"activation\")\n",
        "          ]\n",
        "          for layer in layers:\n",
        "              if layer.activation == tf.keras.activations.relu:\n",
        "                  layer.activation = guided_relu\n",
        "          return gb_model\n",
        "\n",
        "      def guided_backprop(self, image: np.ndarray):\n",
        "          with tf.GradientTape() as tape:\n",
        "              inputs = tf.cast(image, tf.float32)\n",
        "              tape.watch(inputs)\n",
        "              outputs = self.gb_model(inputs)\n",
        "          grads = tape.gradient(outputs, inputs)[0]\n",
        "          return grads\n",
        "\n",
        "  gb = GuidedBackprop(vgg, \"block5_conv3\")\n",
        "\n",
        "  saliency_map = gb.guided_backprop(image[np.newaxis, ...]).numpy()\n",
        "  saliency_map = saliency_map * np.repeat(guided_gradcam[..., np.newaxis], 3, axis=2)\n",
        "\n",
        "  saliency_map -= saliency_map.mean()\n",
        "  saliency_map /= saliency_map.std() + tf.keras.backend.epsilon()\n",
        "  saliency_map *= 0.25\n",
        "  saliency_map += 0.5\n",
        "  saliency_map = np.clip(saliency_map, 0, 1)\n",
        "  saliency_map *= (2 ** 8) - 1\n",
        "  saliency_map = saliency_map.astype(np.uint8)\n",
        "\n",
        "  plt.imshow(saliency_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joxmnPtto3Y3"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Misclassified\"\n",
        "filenames = os.listdir(path)\n",
        "\n",
        "df=pd.DataFrame({'filename':filenames})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngBVoxdvqMKr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcJ08ymmpjVn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for index, row in df.iterrows():\n",
        "    filename = row['filename']\n",
        "    img = np.array(load_img(path + \"/\" + filename, target_size=(224,224)))\n",
        "    if index > 19:\n",
        "      break\n",
        "    plt.subplot(4, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ODleANwMWv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for index, row in df.iterrows():\n",
        "    filename = row['filename']\n",
        "    img = np.array(load_img(path + \"/\" + filename, target_size=(224,224)))\n",
        "    if index > 19:\n",
        "      break\n",
        "    plt.subplot(4, 3, index+1)\n",
        "    gradCam(img)\n",
        "    plt.xlabel(filename)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gky6caMswMaV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for index, row in df.iterrows():\n",
        "    filename = row['filename']  \n",
        "    img = np.array(load_img(path + \"/\" + filename, target_size=(224,224)))\n",
        "    if index > 19:\n",
        "      break\n",
        "    plt.subplot(5, 4, index+1)\n",
        "    guidedGradCam(img)\n",
        "    plt.xlabel(filename)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "VGG16",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}